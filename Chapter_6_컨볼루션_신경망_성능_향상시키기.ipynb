{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 6. 컨볼루션 신경망 - 성능 향상시키기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWGDj9FU3rb/QYB2IyVcWH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SevillaBK/Tensorflow2.0/blob/master/Chapter_6_%EC%BB%A8%EB%B3%BC%EB%A3%A8%EC%85%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D_%EC%84%B1%EB%8A%A5_%ED%96%A5%EC%83%81%EC%8B%9C%ED%82%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10id9bYYLmas",
        "colab_type": "text"
      },
      "source": [
        "컨볼루션 신경망의 성능을 높이기 위해서 사용되는 방법에 대해 알아보겠습니다.<br/>\n",
        "대표적으로 쓰이는 두 방법은 **레이어 많이 쌓기**와 **이미지 보강(Image Augmentation)**입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVQ1ZlQKMC5d",
        "colab_type": "text"
      },
      "source": [
        "# 1. 더 많은 레이어 쌓기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTjeaOppMOHJ",
        "colab_type": "text"
      },
      "source": [
        "딥러닝에서 네트워크의 구조를 깊게 쌓는 것이 가능해진 후 컨볼루션 신경망에서는 컨볼루션 레이어가<br/>\n",
        "중첩된 더 깊은 구조가 계속해서 나타났고, 그 때마다 퍼포먼스가 개선되었습니다.\n",
        "\n",
        "아래에서는 깊은 컨볼루션 레이어를 쌓는 방법 중 하나인 **VGGNet**의 스타일의 신경망으로<br/>\n",
        "Fashion MNIST 데이터셋에 적용해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeMXpYAvLfeN",
        "colab_type": "code",
        "outputId": "8ec2e449-db38-45a9-d9ab-5c6576215d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 텐서플로 불러오기\n",
        "import tensorflow as tf\n",
        "\n",
        "# Fashion MNIST 데이터셋 불러오기\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()\n",
        "\n",
        "# 데이터 스케일링\n",
        "train_X = train_X / 255.0\n",
        "test_X = test_X / 255.0\n",
        "\n",
        "# reshape 이전\n",
        "print(train_X.shape, test_X.shape)\n",
        "\n",
        "train_X = train_X.reshape(-1, 28, 28, 1)\n",
        "test_X = test_X.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# reshape 이후\n",
        "print(train_X.shape, test_X.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n",
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qntBySIfNL-W",
        "colab_type": "code",
        "outputId": "76ca0c63-1445-409d-e03f-b644be509a61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "# VGGNet 스타일의 콘볼루션 신경망 모델\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(input_shape=(28,28,1), kernel_size=(3, 3), filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=128, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=256, padding='valid', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               4719104   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 5,240,842\n",
            "Trainable params: 5,240,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMnFqWY7Phm6",
        "colab_type": "text"
      },
      "source": [
        "VGGNet은 여러 구조로 실험했는데 그 중 19개의 레이어가 겹쳐진 VGG-19가 제일 깊은 구조입니다.<br/>\n",
        "VGG-19는 초반에 컨볼루션 레이어를 2개 겹친 뒤 풀링레이어 1개를 사용하는 패턴을 2차례,<br/>\n",
        "그 후 컨볼루션 레이어를 4개 겹친 뒤 풀링 레이어를 1개 사용하는 패턴을 3차례 반복합니다.\n",
        "\n",
        "![alt text](https://github.com/injo-image/image/blob/master/tensorflow/chapter6/VGG-19.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-h8RWRlN7hu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGGNet 스타일의 컨볼루션 신경망 모델 학습\n",
        "history = model.fit(train_X, train_Y, epochs=25, validation_split=0.25)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM_fLLNZN7e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le46t053N7by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBrdKN4QN7ZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3_LsTv6N7Sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdGPoCdnN7KV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hZGpFQ3N3p6",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}